{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf29e87cb434ebabb6d567c525c8810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Innomer\\.conda\\envs\\gen\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "825f7111dce74d7c9053c3d507fa8f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\")\n",
    "# pipe2 = StableDiffusionImg2ImgPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\")\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1\")\n",
    "pipe2 = StableDiffusionImg2ImgPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1\")\n",
    "pipe = pipe.to(\"cuda\")\n",
    "pipe2 = pipe2.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "strength=0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Innomer\\.conda\\envs\\gen\\Lib\\site-packages\\transformers\\models\\clip\\modeling_clip.py:491: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e3ac26390b43a3a92b42302dea3ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bdb3e23c5aa4f0d850d1dcd2636d244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566e2f4e4c7844ed9cf0981946db9f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m     img\u001b[38;5;241m=\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(prev_image)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m512\u001b[39m,\u001b[38;5;241m512\u001b[39m))\n\u001b[0;32m      9\u001b[0m     prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse the image as the reference and \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mprompt\n\u001b[1;32m---> 10\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mpipe2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstrength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrength\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mimages[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m     image \u001b[38;5;241m=\u001b[39m pipe(prompt)\u001b[38;5;241m.\u001b[39mimages[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Innomer\\.conda\\envs\\gen\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Innomer\\.conda\\envs\\gen\\Lib\\site-packages\\diffusers\\pipelines\\stable_diffusion\\pipeline_stable_diffusion_img2img.py:1104\u001b[0m, in \u001b[0;36mStableDiffusionImg2ImgPipeline.__call__\u001b[1;34m(self, prompt, image, strength, num_inference_steps, timesteps, sigmas, guidance_scale, negative_prompt, num_images_per_prompt, eta, generator, prompt_embeds, negative_prompt_embeds, ip_adapter_image, ip_adapter_image_embeds, output_type, return_dict, cross_attention_kwargs, clip_skip, callback_on_step_end, callback_on_step_end_tensor_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1101\u001b[0m     noise_pred \u001b[38;5;241m=\u001b[39m noise_pred_uncond \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mguidance_scale \u001b[38;5;241m*\u001b[39m (noise_pred_text \u001b[38;5;241m-\u001b[39m noise_pred_uncond)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# compute the previous noisy sample x_t -> x_t-1\u001b[39;00m\n\u001b[1;32m-> 1104\u001b[0m latents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_step_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callback_on_step_end \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1107\u001b[0m     callback_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\Innomer\\.conda\\envs\\gen\\Lib\\site-packages\\diffusers\\schedulers\\scheduling_ddim.py:408\u001b[0m, in \u001b[0;36mDDIMScheduler.step\u001b[1;34m(self, model_output, timestep, sample, eta, use_clipped_model_output, generator, variance_noise, return_dict)\u001b[0m\n\u001b[0;32m    405\u001b[0m alpha_prod_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malphas_cumprod[timestep]\n\u001b[0;32m    406\u001b[0m alpha_prod_t_prev \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malphas_cumprod[prev_timestep] \u001b[38;5;28;01mif\u001b[39;00m prev_timestep \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_alpha_cumprod\n\u001b[1;32m--> 408\u001b[0m beta_prod_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43malpha_prod_t\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;66;03m# 3. compute predicted original sample from predicted noise also called\u001b[39;00m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;66;03m# \"predicted x_0\" of formula (12) from https://arxiv.org/pdf/2010.02502.pdf\u001b[39;00m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mprediction_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepsilon\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Innomer\\.conda\\envs\\gen\\Lib\\site-packages\\torch\\_tensor.py:35\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m(f):\n\u001b[0;32m     33\u001b[0m     assigned \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mWRAPPER_ASSIGNMENTS\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f, assigned\u001b[38;5;241m=\u001b[39massigned)\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m             \u001b[38;5;66;03m# See https://github.com/pytorch/pytorch/issues/75462\u001b[39;00m\n\u001b[0;32m     39\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Generate images from multiple angles\n",
    "object=\"chair\"\n",
    "prompts = [f\"showcase the {object} from the front view\", f\"showcase the {object} from the left view\", f\"showcase the {object} from the back view\", f\"showcase the {object} from the right view\"]\n",
    "images = [] \n",
    "prev_image = None\n",
    "for idx, prompt in enumerate(prompts):\n",
    "    if idx>0:\n",
    "        img=Image.open(prev_image).convert(\"RGB\").resize((512,512))\n",
    "        prompt=\"Use the image as the reference and \"+prompt\n",
    "        image = pipe2(prompt=prompt, image=img,strength=strength).images[0]\n",
    "    else:\n",
    "        image = pipe(prompt).images[0]\n",
    "    image.save(f\"images\\\\view_{idx}.png\")\n",
    "    prev_image = f\"images\\\\view_{idx}.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:39: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:39: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\Innomer\\AppData\\Local\\Temp\\ipykernel_23540\\1444583625.py:39: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  with open('images\\camera_data.json', 'w') as f:\n"
     ]
    }
   ],
   "source": [
    "# Function to generate synthetic camera extrinsics\n",
    "# One-time Function.\n",
    "def create_camera_pose(angle, distance):\n",
    "    # Create a simple rotation around the Y-axis for varying viewpoints\n",
    "    theta = np.radians(angle)\n",
    "    cam_position = np.array([distance * np.sin(theta), 0, distance * np.cos(theta)])\n",
    "    \n",
    "    forward = -cam_position / np.linalg.norm(cam_position)\n",
    "    up = np.array([0, 1, 0])\n",
    "    right = np.cross(up, forward)\n",
    "    \n",
    "    # Rotation and translation matrix (extrinsic)\n",
    "    extrinsic_matrix = np.identity(4)\n",
    "    extrinsic_matrix[0:3, 0] = right\n",
    "    extrinsic_matrix[0:3, 1] = up\n",
    "    extrinsic_matrix[0:3, 2] = forward\n",
    "    extrinsic_matrix[0:3, 3] = cam_position\n",
    "    \n",
    "    return extrinsic_matrix\n",
    "\n",
    "angles = [0, 90, 270, 360]\n",
    "distance = 3.0\n",
    "\n",
    "camera_angle_x = np.radians(60)\n",
    "\n",
    "frames = []\n",
    "for i, angle in enumerate(angles):\n",
    "    pose = create_camera_pose(angle, distance)\n",
    "    frames.append({\n",
    "        \"file_path\": f\"view_{i}.png\",\n",
    "        \"transform_matrix\": pose.tolist()\n",
    "    })\n",
    "\n",
    "camera_data = {\n",
    "    \"camera_angle_x\": camera_angle_x,\n",
    "    \"frames\": frames\n",
    "}\n",
    "\n",
    "with open('images\\camera_data.json', 'w') as f:\n",
    "    json.dump(camera_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%../instant-ngp/instant-ngp.exe ./images/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
